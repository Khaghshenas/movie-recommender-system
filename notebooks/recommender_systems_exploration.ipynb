{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa4e398-31e3-4615-b0df-6bbbb1a23078",
   "metadata": {},
   "source": [
    "# Exploring and Evaluating Recommender Systems on MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6eb0a-d646-47b3-927c-8f7e95503c51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "This notebook explores multiple recommender system approaches with increasing modeling complexity. Classical methods, including Content-Based Filtering and User-Based Collaborative Filtering, are presented as baseline techniques. More advanced models—Item-Based Collaborative Filtering, Matrix Factorization via SVD, and a neural autoencoder—are evaluated more rigorously using standard Top-N recommendation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b841cf-c4a6-48c7-bb96-b5a4a9fcf664",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569ad18-6576-45be-b293-926319ca9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71cf9f-2c78-4211-bf8e-5c2078e821ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the root folder to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from app.etl import run_etl\n",
    "\n",
    "#Paths to the dataset files\n",
    "file_paths = {\n",
    "    'ratings': '../data/ml_100k/u.data',\n",
    "    'movies': '../data/ml_100k/u.item'\n",
    "}\n",
    "\n",
    "# Run the ETL pipeline\n",
    "preprocessed_data = run_etl(file_paths, save_path='../app/preprocessed_movielens.csv')\n",
    "\n",
    "# Check the original data\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570152ac-2d9e-4fdd-ab61-8e3785ee8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smaller and pre processed MovieLens dataset\n",
    "ratings = pd.read_csv('../data/ml_100k/u.data', sep='\\t',\n",
    "                      names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "movies = pd.read_csv('../data/ml_100k/u.item', sep='|', encoding='latin-1', header=None,\n",
    "                     names=['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "                            'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "                            'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "                            'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
    "\n",
    "# Encode genres\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary',\n",
    "              'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',\n",
    "              'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "genres_encoded = movies[genre_cols].copy()\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = cosine_similarity(genres_encoded)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=movies['movie_id'], columns=movies['movie_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcb204-48ef-4b4d-97b6-0995d4261c5d",
   "metadata": {},
   "source": [
    "#### Train / Test Split (Per User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491896a-e7cb-4f5e-b65e-ff146cde176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_user(ratings, test_ratio=0.2, min_ratings=5):\n",
    "    train, test = [], []\n",
    "\n",
    "    for user_id, group in ratings.groupby(\"user_id\"):\n",
    "        if len(group) < min_ratings:\n",
    "            continue\n",
    "\n",
    "        group = group.sample(frac=1, random_state=42)\n",
    "        split_idx = int(len(group) * (1 - test_ratio))\n",
    "\n",
    "        train.append(group.iloc[:split_idx])\n",
    "        test.append(group.iloc[split_idx:])\n",
    "\n",
    "    return pd.concat(train), pd.concat(test)\n",
    "\n",
    "ratings_df = ratings.copy()\n",
    "train_df, test_df = train_test_split_by_user(ratings_df)\n",
    "\n",
    "# Build user-item matrix\n",
    "#user_item_matrix = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "\n",
    "user_item_matrix = train_df.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e079f-cea2-4a2c-b7fa-880cea65217f",
   "metadata": {},
   "source": [
    "#### Ground Truth (What Each User Actually Liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fc778-3594-4fba-84b6-0e1d3604cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ground_truth(test_df, threshold=4.0):\n",
    "    ground_truth = defaultdict(set)\n",
    "\n",
    "    for row in test_df.itertuples():\n",
    "        if row.rating >= threshold:\n",
    "            ground_truth[row.user_id].add(row.movie_id)\n",
    "\n",
    "    return ground_truth\n",
    "\n",
    "ground_truth = build_ground_truth(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c0587-a723-44de-9d00-75e490374853",
   "metadata": {},
   "source": [
    "# 0. Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09517475-f39f-4efa-a1be-8717a911202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for Content-Based Filtering (per user)\n",
    "def content_based_recommend(user_id, user_item_matrix, similarity_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a user based on content similarity\n",
    "    Only works if the user exists in user_item_matrix (train_df)\n",
    "    \"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return []  # user not in training set\n",
    "\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        if rating > 0:\n",
    "            sim_scores = similarity_df[movie_id]\n",
    "            for other_movie_id, sim in sim_scores.items():\n",
    "                if other_movie_id not in user_ratings.index or user_ratings[other_movie_id] == 0:\n",
    "                    scores[other_movie_id] += sim * rating\n",
    "\n",
    "    recommended_movies = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_movies = [movie_id for movie_id, _ in recommended_movies[:top_n]]\n",
    "    return top_movies\n",
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "top_n = 10\n",
    "cbf_recommendations = content_based_recommend(user_id, user_item_matrix, similarity_df, top_n=top_n)\n",
    "print(f\"Top-{top_n} Content-Based Recommendations for User {user_id}: {cbf_recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0332c9-b00c-4ed2-969c-558caad5d93a",
   "metadata": {},
   "source": [
    "# 1. User-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef030225-95b5-4609-b1d8-8f7501d5b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute User Similarity\n",
    "# Cosine similarity between users\n",
    "user_similarity = cosine_similarity(user_item_matrix)\n",
    "\n",
    "# DataFrame for easy lookup\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "# Wrapper for User-Based Filtering (per user)\n",
    "def user_cf_recommend_wrapper(user_id, user_item_matrix, user_similarity_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a given user\n",
    "    using User-Based Collaborative Filtering.\n",
    "    \"\"\"\n",
    "    # Similarity scores for target user\n",
    "    similar_users = user_similarity_df.loc[user_id]\n",
    "\n",
    "    # Compute weighted ratings\n",
    "    weighted_ratings = np.dot(similar_users, user_item_matrix) / similar_users.sum()\n",
    "\n",
    "    # Build recommendations DataFrame\n",
    "    recommendations = pd.DataFrame({\n",
    "        'movie_id': user_item_matrix.columns,\n",
    "        'score': weighted_ratings\n",
    "    }).sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Exclude already rated movies\n",
    "    user_rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "    recommendations = recommendations[~recommendations['movie_id'].isin(user_rated_movies)]\n",
    "\n",
    "    # Return top_n movie IDs (evaluation-ready)\n",
    "    return recommendations['movie_id'].head(top_n).tolist()\n",
    "\n",
    "# Show movie titles\n",
    "def user_cf_recommend_demo(user_id, user_item_matrix, user_similarity_df, movies, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie titles for demonstration.\n",
    "    \"\"\"\n",
    "    movie_ids = user_cf_recommend_wrapper(user_id, user_item_matrix, user_similarity_df, top_n)\n",
    "    return movies[movies['movie_id'].isin(movie_ids)][['movie_id','title']]\n",
    "\n",
    "# Example Usage\n",
    "user_id = 1\n",
    "user_recommendations_demo = user_cf_recommend_demo(user_id, user_item_matrix, user_similarity_df, movies)\n",
    "print(\"User-Based Recommendations (Titles):\")\n",
    "print(user_recommendations_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4b99f-e8e3-42ba-993a-a73947208eeb",
   "metadata": {},
   "source": [
    "# 2. Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a33950-251b-4063-8625-bc508bcde26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose user-item matrix to item-user matrix\n",
    "item_user_matrix = user_item_matrix.T\n",
    "\n",
    "# Compute cosine similarity between items\n",
    "item_similarity = cosine_similarity(item_user_matrix)\n",
    "\n",
    "# Wrap it in a DataFrame for easy access\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=item_user_matrix.index,\n",
    "    columns=item_user_matrix.index\n",
    ")\n",
    "\n",
    "# print(item_similarity_df.head())\n",
    "\n",
    "# Wrapper for Item-Based Filtering (per user)\n",
    "def item_cf_recommend(user_id, user_item_matrix, item_similarity_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a user using Item-Based CF.\n",
    "    Excludes movies already rated by the user.\n",
    "    \"\"\"\n",
    "    # User's ratings\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "\n",
    "    # Compute item-based scores\n",
    "    scores = np.dot(user_ratings, item_similarity_df) / np.array([np.abs(item_similarity_df).sum(axis=1)])\n",
    "    scores = scores.flatten()\n",
    "\n",
    "    # Create DataFrame with movie scores\n",
    "    recommendations = pd.DataFrame({\n",
    "        'movie_id': user_item_matrix.columns,\n",
    "        'score': scores\n",
    "    }).sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Exclude already rated movies\n",
    "    user_rated_movies = user_ratings[user_ratings > 0].index\n",
    "    recommendations = recommendations[~recommendations['movie_id'].isin(user_rated_movies)]\n",
    "\n",
    "    # Return top-N movie IDs only (for evaluation)\n",
    "    return recommendations['movie_id'].head(top_n).tolist()\n",
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "top_n = 10\n",
    "item_recommendations = item_cf_recommend(user_id, user_item_matrix, item_similarity_df, top_n=top_n)\n",
    "\n",
    "print(f\"Top-{top_n} Item-Based CF Recommendations for User {user_id}:\")\n",
    "print(item_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990d119-cc2b-4130-a7ea-ad93d97ac50e",
   "metadata": {},
   "source": [
    "# 3. Matrix Factorization (e.g., SVD) Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da97e6-9769-46ee-941a-1998fad9ed0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare User-Item Matrix\n",
    "# Ensure all ratings are numeric and fill missing values with 0\n",
    "user_item_matrix = user_item_matrix.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Apply Truncated SVD\n",
    "n_components = 20  # Number of latent features\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "\n",
    "# Compute latent factors\n",
    "user_features = svd.fit_transform(user_item_matrix)  # shape: (n_users, n_components)\n",
    "item_features = svd.components_                       # shape: (n_components, n_items)\n",
    "\n",
    "# Reconstruct the Approximate Ratings\n",
    "reconstructed_matrix = np.dot(user_features, item_features)\n",
    "\n",
    "# Wrap as DataFrame for easy access\n",
    "predicted_ratings = pd.DataFrame(\n",
    "    reconstructed_matrix,\n",
    "    index=user_item_matrix.index,\n",
    "    columns=user_item_matrix.columns\n",
    ")\n",
    "\n",
    "# Wrapper for SVD Filtering (per user)\n",
    "def svd_recommend_wrapper(user_id, predicted_ratings, user_item_matrix, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a given user,\n",
    "    excluding already rated movies.\n",
    "    \"\"\"\n",
    "    # Get predicted ratings for the user\n",
    "    user_predicted_ratings = predicted_ratings.loc[user_id]\n",
    "\n",
    "    # Identify already rated movies\n",
    "    user_rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "\n",
    "    # Exclude already rated movies\n",
    "    recommendations = user_predicted_ratings[~user_predicted_ratings.index.isin(user_rated_movies)]\n",
    "\n",
    "    # Return top_n movie IDs only\n",
    "    return recommendations.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "\n",
    "# Example Usage\n",
    "user_id = 1\n",
    "svd_recommendations = svd_recommend_wrapper(user_id, predicted_ratings, user_item_matrix, top_n=10)\n",
    "print(f\"SVD Recommendations for User {user_id}:\")\n",
    "print(svd_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da9414-d85a-45cf-a513-bb04b48563ed",
   "metadata": {},
   "source": [
    "# 4. Deep Learning-Based Recommendation: Autoencoders for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad36b9f-eea0-4cbf-be8f-4e16f846e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbabb79-892b-40a3-a6f3-32301daf7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Train/Test user-item matrix (row-wise)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_train = scaler.fit_transform(user_item_matrix)\n",
    "normalized_train = pd.DataFrame(normalized_train, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Build test user-item matrix (same shape as train, fill missing with 0)\n",
    "user_item_matrix_test = test_df.pivot(index='user_id', columns='movie_id', values='rating').reindex(\n",
    "    index=user_item_matrix.index, columns=user_item_matrix.columns, fill_value=0\n",
    ")\n",
    "\n",
    "normalized_test = scaler.transform(user_item_matrix_test)\n",
    "normalized_test = pd.DataFrame(normalized_test, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "\n",
    "# Define Autoencoder Architecture\n",
    "n_movies = user_item_matrix.shape[1]\n",
    "\n",
    "autoencoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(n_movies,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_movies, activation='sigmoid')\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    normalized_train.values, normalized_train.values,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(normalized_test.values, normalized_test.values),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict reconstructed user-item matrix\n",
    "reconstructed_matrix = autoencoder.predict(normalized_train.values)\n",
    "predicted_ratings = pd.DataFrame(reconstructed_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Wrapper for Autoencoder (per user)\n",
    "def autoencoder_recommend_wrapper(user_id, predicted_ratings, user_item_matrix, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a given user,\n",
    "    excluding already rated movies.\n",
    "    \"\"\"\n",
    "    user_predicted_ratings = predicted_ratings.loc[user_id]\n",
    "    user_rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "    recommendations = user_predicted_ratings[~user_predicted_ratings.index.isin(user_rated_movies)]\n",
    "    return recommendations.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "\n",
    "# Example usage\n",
    "top_movies = autoencoder_recommend_wrapper(1, predicted_ratings, user_item_matrix, top_n=10)\n",
    "print(\"Autoencoder Top-10 Recommendations (movie IDs):\")\n",
    "print(top_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f754f-2d8c-4f92-85bf-fcb690c09745",
   "metadata": {},
   "source": [
    "# Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4815378-9684-496a-9079-80f46174db2a",
   "metadata": {},
   "source": [
    "#### Top-N Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91966ea6-342d-45fd-ae7b-0aa172f57c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    if not recommended:\n",
    "        return 0.0\n",
    "    return len(set(recommended) & relevant) / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    return len(set(recommended) & relevant) / len(relevant)\n",
    "\n",
    "def average_precision_at_k(recommended, relevant, k):\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "\n",
    "    for i, item in enumerate(recommended[:k]):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            score += hits / (i + 1)\n",
    "\n",
    "    return score / min(len(relevant), k) if relevant else 0.0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended[:k]):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "\n",
    "    ideal_dcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "def hit_rate_at_k(recommended, relevant, k):\n",
    "    return int(len(set(recommended[:k]) & relevant) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5267e00-22de-4c6c-92f3-e994389e65c2",
   "metadata": {},
   "source": [
    "#### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea97ffa-38bf-42ae-9c8a-8b9fa21ea6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(recommender_fn, ground_truth, k=10):\n",
    "    precisions, recalls, maps, ndcgs, hits = [], [], [], [], []\n",
    "\n",
    "    for user_id, relevant_items in ground_truth.items():\n",
    "        recommended_items = recommender_fn(user_id)\n",
    "\n",
    "        precisions.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "        recalls.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "        maps.append(average_precision_at_k(recommended_items, relevant_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "        hits.append(hit_rate_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    return {\n",
    "        \"Precision@K\": np.mean(precisions),\n",
    "        \"Recall@K\": np.mean(recalls),\n",
    "        \"MAP@K\": np.mean(maps),\n",
    "        \"NDCG@K\": np.mean(ndcgs),\n",
    "        \"HitRate@K\": np.mean(hits),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ae33a-af5e-40f7-a021-0a68fd3a9d56",
   "metadata": {},
   "source": [
    "#### Run Comparison Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eca6eb-c906-455a-b4a6-d0c2a6c7df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Item based CF\n",
    "item_cf = ?(train_df, top_n=10)\n",
    "results[\"item_cf\"] = evaluate_model(item_cf_recommender, ground_truth, k=10)\n",
    "\n",
    "# SVD CF\n",
    "item_cf = ?(train_df, top_n=10)\n",
    "results[\"item_cf\"] = evaluate_model(item_cf_recommender, ground_truth, k=10)\n",
    "\n",
    "\n",
    "#Autoencoder\n",
    "item_cf = ?(train_df, top_n=10)\n",
    "results[\"item_cf\"] = evaluate_model(item_cf_recommender, ground_truth, k=10)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66192f-686f-4dfd-97eb-f5cf9a37b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test_recommender)",
   "language": "python",
   "name": "test_recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
