{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa4e398-31e3-4615-b0df-6bbbb1a23078",
   "metadata": {},
   "source": [
    "# Exploring and Evaluating Recommender Systems on MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6eb0a-d646-47b3-927c-8f7e95503c51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "This notebook explores multiple recommender system approaches with increasing modeling complexity. Classical methods, including Content-Based Filtering and User-Based Collaborative Filtering, are presented as baseline techniques. The methods Item-Based Collaborative Filtering and the neural autoencoder—are evaluated more rigorously using standard Top-N recommendation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b841cf-c4a6-48c7-bb96-b5a4a9fcf664",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4569ad18-6576-45be-b293-926319ca9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea71cf9f-2c78-4211-bf8e-5c2078e821ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the root folder to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from app.etl import run_etl\n",
    "\n",
    "#Paths to the dataset files\n",
    "file_paths = {\n",
    "    'ratings': '../data/ml_100k/u.data',\n",
    "    'movies': '../data/ml_100k/u.item'\n",
    "}\n",
    "\n",
    "# Run the ETL pipeline\n",
    "#preprocessed_data = run_etl(file_paths, save_path='../app/preprocessed_movielens.csv')\n",
    "\n",
    "# Check the original data\n",
    "#print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570152ac-2d9e-4fdd-ab61-8e3785ee8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smaller and pre processed MovieLens dataset\n",
    "ratings = pd.read_csv('../data/ml_100k/u.data', sep='\\t',\n",
    "                      names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "movies = pd.read_csv('../data/ml_100k/u.item', sep='|', encoding='latin-1', header=None,\n",
    "                     names=['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "                            'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "                            'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "                            'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
    "\n",
    "# Encode genres\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary',\n",
    "              'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',\n",
    "              'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "genres_encoded = movies[genre_cols].copy()\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = cosine_similarity(genres_encoded)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=movies['movie_id'], columns=movies['movie_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcb204-48ef-4b4d-97b6-0995d4261c5d",
   "metadata": {},
   "source": [
    "#### Train / Test Split (Per User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9491896a-e7cb-4f5e-b65e-ff146cde176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_user(ratings, test_ratio=0.2, min_ratings=5):\n",
    "    train, test = [], []\n",
    "\n",
    "    for user_id, group in ratings.groupby(\"user_id\"):\n",
    "        if len(group) < min_ratings:\n",
    "            continue\n",
    "\n",
    "        group = group.sample(frac=1, random_state=42)\n",
    "        split_idx = int(len(group) * (1 - test_ratio))\n",
    "\n",
    "        train.append(group.iloc[:split_idx])\n",
    "        test.append(group.iloc[split_idx:])\n",
    "\n",
    "    return pd.concat(train), pd.concat(test)\n",
    "\n",
    "ratings_df = ratings.copy()\n",
    "train_df, test_df = train_test_split_by_user(ratings_df)\n",
    "\n",
    "# Build user-item matrix\n",
    "#user_item_matrix = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "\n",
    "user_item_matrix = train_df.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e079f-cea2-4a2c-b7fa-880cea65217f",
   "metadata": {},
   "source": [
    "#### Ground Truth (What Each User Actually Liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44fc778-3594-4fba-84b6-0e1d3604cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ground_truth(test_df, threshold=4.0):\n",
    "    ground_truth = defaultdict(set)\n",
    "\n",
    "    for row in test_df.itertuples():\n",
    "        if row.rating >= threshold:\n",
    "            ground_truth[row.user_id].add(row.movie_id)\n",
    "\n",
    "    return ground_truth\n",
    "\n",
    "ground_truth = build_ground_truth(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c0587-a723-44de-9d00-75e490374853",
   "metadata": {},
   "source": [
    "# 0. Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09517475-f39f-4efa-a1be-8717a911202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Content-Based Recommendations for User 1: [337, 316, 345, 347, 382, 409, 481, 522, 523, 598]\n"
     ]
    }
   ],
   "source": [
    "# Wrapper for Content-Based Filtering (per user)\n",
    "def content_based_recommend(user_id, cb_matrix, similarity_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a user based on content similarity\n",
    "    Only works if the user exists in user_item_matrix (train_df)\n",
    "    \"\"\"\n",
    "    if user_id not in cb_matrix.index:\n",
    "        return []  # user not in training set\n",
    "\n",
    "    user_ratings = cb_matrix.loc[user_id]\n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        if rating > 0:\n",
    "            sim_scores = similarity_df[movie_id]\n",
    "            for other_movie_id, sim in sim_scores.items():\n",
    "                if other_movie_id not in user_ratings.index or user_ratings[other_movie_id] == 0:\n",
    "                    scores[other_movie_id] += sim * rating\n",
    "\n",
    "    recommended_movies = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_movies = [movie_id for movie_id, _ in recommended_movies[:top_n]]\n",
    "    return top_movies\n",
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "top_n = 10\n",
    "cb_matrix = user_item_matrix.copy()\n",
    "\n",
    "cbf_recommendations = content_based_recommend(user_id, cb_matrix, similarity_df, top_n=top_n)\n",
    "print(f\"Top-{top_n} Content-Based Recommendations for User {user_id}: {cbf_recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0332c9-b00c-4ed2-969c-558caad5d93a",
   "metadata": {},
   "source": [
    "# 1. User-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef030225-95b5-4609-b1d8-8f7501d5b7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Based Recommendations (Titles):\n",
      "     movie_id                              title\n",
      "0           1                   Toy Story (1995)\n",
      "6           7              Twelve Monkeys (1995)\n",
      "63         64   Shawshank Redemption, The (1994)\n",
      "88         89                Blade Runner (1982)\n",
      "95         96  Terminator 2: Judgment Day (1991)\n",
      "120       121      Independence Day (ID4) (1996)\n",
      "126       127              Godfather, The (1972)\n",
      "203       204          Back to the Future (1985)\n",
      "317       318            Schindler's List (1993)\n",
      "422       423  E.T. the Extra-Terrestrial (1982)\n"
     ]
    }
   ],
   "source": [
    "# Compute User Similarity\n",
    "# Cosine similarity between users\n",
    "ub_matrix = user_item_matrix.copy()\n",
    "user_similarity = cosine_similarity(ub_matrix)\n",
    "\n",
    "# DataFrame for easy lookup\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=ub_matrix.index, columns=ub_matrix.index)\n",
    "\n",
    "# Wrapper for User-Based Filtering (per user)\n",
    "def user_cf_recommend_wrapper(user_id, ub_matrix, user_similarity_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a given user\n",
    "    using User-Based Collaborative Filtering.\n",
    "    \"\"\"\n",
    "    # Similarity scores for target user\n",
    "    similar_users = user_similarity_df.loc[user_id]\n",
    "\n",
    "    # Compute weighted ratings\n",
    "    weighted_ratings = np.dot(similar_users, ub_matrix) / similar_users.sum()\n",
    "\n",
    "    # Build recommendations DataFrame\n",
    "    recommendations = pd.DataFrame({\n",
    "        'movie_id': ub_matrix.columns,\n",
    "        'score': weighted_ratings\n",
    "    }).sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Exclude already rated movies\n",
    "    user_rated_movies = ub_matrix.loc[user_id][ub_matrix.loc[user_id] > 0].index\n",
    "    recommendations = recommendations[~recommendations['movie_id'].isin(user_rated_movies)]\n",
    "\n",
    "    # Return top_n movie IDs (evaluation-ready)\n",
    "    return recommendations['movie_id'].head(top_n).tolist()\n",
    "\n",
    "# Show movie titles\n",
    "def user_cf_recommend_demo(user_id, ub_matrix, user_similarity_df, movies, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie titles for demonstration.\n",
    "    \"\"\"\n",
    "    movie_ids = user_cf_recommend_wrapper(user_id, ub_matrix, user_similarity_df, top_n)\n",
    "    return movies[movies['movie_id'].isin(movie_ids)][['movie_id','title']]\n",
    "\n",
    "# Example Usage\n",
    "user_id = 1\n",
    "user_recommendations_demo = user_cf_recommend_demo(user_id, ub_matrix, user_similarity_df, movies)\n",
    "print(\"User-Based Recommendations (Titles):\")\n",
    "print(user_recommendations_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4b99f-e8e3-42ba-993a-a73947208eeb",
   "metadata": {},
   "source": [
    "# 2. Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a33950-251b-4063-8625-bc508bcde26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Item-Based CF Recommendations for User 1:\n",
      "[1619, 1526, 1618, 1614, 711, 1682, 1476, 963, 695, 1354]\n"
     ]
    }
   ],
   "source": [
    "# Transpose user-item matrix to item-user matrix\n",
    "item_cf_matrix = user_item_matrix.copy()\n",
    "item_user_matrix = item_cf_matrix.T\n",
    "\n",
    "# Compute cosine similarity between items\n",
    "item_similarity = cosine_similarity(item_user_matrix)\n",
    "\n",
    "# Wrap it in a DataFrame for easy access\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=item_user_matrix.index,\n",
    "    columns=item_user_matrix.index\n",
    ")\n",
    "\n",
    "# print(item_similarity_df.head())\n",
    "\n",
    "# Wrapper for Item-Based Filtering (per user)\n",
    "def item_cf_recommend(user_id, item_cf_matrix, item_similarity_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top_n recommended movie IDs for a user using Item-Based CF.\n",
    "    Excludes movies already rated by the user.\n",
    "    \"\"\"\n",
    "    # User's ratings\n",
    "    user_ratings = item_cf_matrix.loc[user_id]\n",
    "\n",
    "    # Compute item-based scores\n",
    "    scores = np.dot(user_ratings, item_similarity_df) / np.array([np.abs(item_similarity_df).sum(axis=1)])\n",
    "    scores = scores.flatten()\n",
    "\n",
    "    # Create DataFrame with movie scores\n",
    "    recommendations = pd.DataFrame({\n",
    "        'movie_id': item_cf_matrix.columns,\n",
    "        'score': scores\n",
    "    }).sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Exclude already rated movies\n",
    "    user_rated_movies = user_ratings[user_ratings > 0].index\n",
    "    recommendations = recommendations[~recommendations['movie_id'].isin(user_rated_movies)]\n",
    "\n",
    "    # Return top-N movie IDs only (for evaluation)\n",
    "    return recommendations['movie_id'].head(top_n).tolist()\n",
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "top_n = 10\n",
    "item_recommendations = item_cf_recommend(user_id, item_cf_matrix, item_similarity_df, top_n=top_n)\n",
    "\n",
    "print(f\"Top-{top_n} Item-Based CF Recommendations for User {user_id}:\")\n",
    "print(item_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da9414-d85a-45cf-a513-bb04b48563ed",
   "metadata": {},
   "source": [
    "# 4. Deep Learning-Based Recommendation: Autoencoders for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad36b9f-eea0-4cbf-be8f-4e16f846e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P313204\\AppData\\Local\\miniconda3\\envs\\recommender\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4902ff21-60b9-480f-a58f-c479c3429f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    masked_error = squared_error * mask\n",
    "    return tf.reduce_sum(masked_error) / tf.reduce_sum(mask)\n",
    "\n",
    "def bpr_loss(y_true, y_pred):\n",
    "    pos = tf.boolean_mask(y_pred, y_true > 0)\n",
    "    neg = tf.boolean_mask(y_pred, y_true == 0)\n",
    "    neg = tf.random.shuffle(neg)[:tf.shape(pos)[0]]\n",
    "    return -tf.reduce_mean(tf.math.log(tf.nn.sigmoid(pos - neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbabb79-892b-40a3-a6f3-32301daf7f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.6796 - val_loss: 0.6963\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6884 - val_loss: 0.6685\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6988 - val_loss: 0.6438\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6983 - val_loss: 0.6311\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6982 - val_loss: 0.6256\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6977 - val_loss: 0.6226\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6969 - val_loss: 0.6209\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6964 - val_loss: 0.6199\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6959 - val_loss: 0.6191\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6955 - val_loss: 0.6189\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6954 - val_loss: 0.6188\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6948 - val_loss: 0.6181\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6945 - val_loss: 0.6176\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6939 - val_loss: 0.6174\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6935 - val_loss: 0.6165\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6935 - val_loss: 0.6167\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6931 - val_loss: 0.6160\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6932 - val_loss: 0.6164\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6928 - val_loss: 0.6162\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6924 - val_loss: 0.6158\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6924 - val_loss: 0.6154\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6922 - val_loss: 0.6155\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6919 - val_loss: 0.6155\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6921 - val_loss: 0.6155\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6918 - val_loss: 0.6153\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6920 - val_loss: 0.6151\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6917 - val_loss: 0.6155\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6914 - val_loss: 0.6152\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6915 - val_loss: 0.6153\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6916 - val_loss: 0.6152\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6913 - val_loss: 0.6147\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6911 - val_loss: 0.6145\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6911 - val_loss: 0.6146\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6908 - val_loss: 0.6145\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6913 - val_loss: 0.6142\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6915 - val_loss: 0.6141\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6916 - val_loss: 0.6143\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6913 - val_loss: 0.6148\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6913 - val_loss: 0.6148\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6913 - val_loss: 0.6150\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6915 - val_loss: 0.6148\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6914 - val_loss: 0.6150\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6914 - val_loss: 0.6149\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6911 - val_loss: 0.6149\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6913 - val_loss: 0.6153\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6913 - val_loss: 0.6156\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6916 - val_loss: 0.6158\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6912 - val_loss: 0.6162\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6915 - val_loss: 0.6162\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6916 - val_loss: 0.6163\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6918 - val_loss: 0.6161\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6917 - val_loss: 0.6164\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6917 - val_loss: 0.6162\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6916 - val_loss: 0.6160\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6918 - val_loss: 0.6160\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6914 - val_loss: 0.6166\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6917 - val_loss: 0.6161\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6915 - val_loss: 0.6163\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6915 - val_loss: 0.6161\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6914 - val_loss: 0.6165\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6916 - val_loss: 0.6164\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6917 - val_loss: 0.6165\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6917 - val_loss: 0.6163\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6918 - val_loss: 0.6160\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6916 - val_loss: 0.6161\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6917 - val_loss: 0.6163\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6918 - val_loss: 0.6171\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6918 - val_loss: 0.6171\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6919 - val_loss: 0.6167\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6921 - val_loss: 0.6173\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6921 - val_loss: 0.6176\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6919 - val_loss: 0.6170\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6920 - val_loss: 0.6173\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6920 - val_loss: 0.6179\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6923 - val_loss: 0.6179\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6923 - val_loss: 0.6184\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6924 - val_loss: 0.6187\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6924 - val_loss: 0.6188\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6925 - val_loss: 0.6188\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6926 - val_loss: 0.6190\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6930 - val_loss: 0.6193\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6930 - val_loss: 0.6199\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6930 - val_loss: 0.6200\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6933 - val_loss: 0.6200\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6932 - val_loss: 0.6197\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6931 - val_loss: 0.6200\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6932 - val_loss: 0.6202\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6932 - val_loss: 0.6198\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6932 - val_loss: 0.6203\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6932 - val_loss: 0.6204\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6932 - val_loss: 0.6204\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6931 - val_loss: 0.6201\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6931 - val_loss: 0.6208\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6931 - val_loss: 0.6206\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6931 - val_loss: 0.6206\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6932 - val_loss: 0.6211\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6931 - val_loss: 0.6212\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6931 - val_loss: 0.6212\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6931 - val_loss: 0.6221\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6933 - val_loss: 0.6227\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Autoencoder Top-10 Recommendations (movie IDs):\n",
      "[1647, 138, 136, 130, 128, 127, 125, 121, 113, 109]\n"
     ]
    }
   ],
   "source": [
    "# Normalize ratings to 0-1 for autoencoder\n",
    "autoencoder_matrix = user_item_matrix.copy()\n",
    "autoencoder_matrix = autoencoder_matrix / autoencoder_matrix.max().max()\n",
    "train_matrix = autoencoder_matrix.copy()\n",
    "test_matrix = test_df.pivot(index='user_id', columns='movie_id', values='rating') \\\n",
    "                   .reindex(index=train_matrix.index, columns=train_matrix.columns, fill_value=0)\n",
    "test_matrix = test_matrix / user_item_matrix.max().max()\n",
    "\n",
    "noise_factor = 0.3\n",
    "noisy_train = train_matrix + noise_factor * np.random.randn(*train_matrix.shape)\n",
    "noisy_train = np.clip(noisy_train, 0, 1)\n",
    "\n",
    "# Define deep autoencoder\n",
    "n_movies = train_matrix.shape[1]\n",
    "\n",
    "autoencoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(n_movies,)),\n",
    "    \n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # bottleneck\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_movies, activation='sigmoid')  # output between 0-1\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=bpr_loss)\n",
    "\n",
    "# Train\n",
    "history = autoencoder.fit(\n",
    "    noisy_train.values, train_matrix.values,\n",
    "    epochs=100,      \n",
    "    batch_size=128, \n",
    "    validation_data=(test_matrix.values, test_matrix.values),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "reconstructed_matrix = autoencoder.predict(train_matrix.values)\n",
    "autoencoder_predicted_ratings = pd.DataFrame(reconstructed_matrix, index=train_matrix.index, columns=train_matrix.columns)\n",
    "\n",
    "# Recommendation wrapper\n",
    "def autoencoder_recommend_wrapper(user_id, autoencoder_predicted_ratings, train_matrix, top_n=10):\n",
    "    user_autoencoder_predicted_ratings = autoencoder_predicted_ratings.loc[user_id]\n",
    "    user_rated_movies = train_matrix.loc[user_id][train_matrix.loc[user_id] > 0].index\n",
    "    recommendations = user_autoencoder_predicted_ratings[~user_autoencoder_predicted_ratings.index.isin(user_rated_movies)]\n",
    "    return recommendations.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "\n",
    "# Example Usage\n",
    "top_movies = autoencoder_recommend_wrapper(1, autoencoder_predicted_ratings, train_matrix, top_n=10)\n",
    "print(\"Autoencoder Top-10 Recommendations (movie IDs):\")\n",
    "print(top_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f754f-2d8c-4f92-85bf-fcb690c09745",
   "metadata": {},
   "source": [
    "# Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4815378-9684-496a-9079-80f46174db2a",
   "metadata": {},
   "source": [
    "#### Top-N Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91966ea6-342d-45fd-ae7b-0aa172f57c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    if not recommended:\n",
    "        return 0.0\n",
    "    return len(set(recommended) & relevant) / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    return len(set(recommended) & relevant) / len(relevant)\n",
    "\n",
    "def average_precision_at_k(recommended, relevant, k):\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "\n",
    "    for i, item in enumerate(recommended[:k]):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            score += hits / (i + 1)\n",
    "\n",
    "    return score / min(len(relevant), k) if relevant else 0.0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended[:k]):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "\n",
    "    ideal_dcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "def hit_rate_at_k(recommended, relevant, k):\n",
    "    return int(len(set(recommended[:k]) & relevant) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5267e00-22de-4c6c-92f3-e994389e65c2",
   "metadata": {},
   "source": [
    "#### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea97ffa-38bf-42ae-9c8a-8b9fa21ea6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(recommended_items, ground_truth, k=10):\n",
    "    precisions, recalls, maps, ndcgs, hits = [], [], [], [], []\n",
    "\n",
    "    for user_id, relevant_items in ground_truth.items():\n",
    "\n",
    "        if user_id not in recommended_items:\n",
    "            continue\n",
    "\n",
    "        user_recs = recommended_items[user_id]\n",
    "\n",
    "        precisions.append(precision_at_k(user_recs, relevant_items, k))\n",
    "        recalls.append(recall_at_k(user_recs, relevant_items, k))\n",
    "        maps.append(average_precision_at_k(user_recs, relevant_items, k))\n",
    "        ndcgs.append(ndcg_at_k(user_recs, relevant_items, k))\n",
    "        hits.append(hit_rate_at_k(user_recs, relevant_items, k))\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Precision@K\": np.mean(precisions),\n",
    "        \"Recall@K\": np.mean(recalls),\n",
    "        \"MAP@K\": np.mean(maps),\n",
    "        \"NDCG@K\": np.mean(ndcgs),\n",
    "        \"HitRate@K\": np.mean(hits),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ae33a-af5e-40f7-a021-0a68fd3a9d56",
   "metadata": {},
   "source": [
    "#### Run Comparison Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0eca6eb-c906-455a-b4a6-d0c2a6c7df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_users = list(ground_truth.keys())\n",
    "\n",
    "item_cf_recommendations = {}\n",
    "\n",
    "for user_id in eval_users:\n",
    "    item_cf_recommendations[user_id] = item_cf_recommend(\n",
    "        user_id,\n",
    "        item_cf_matrix,\n",
    "        item_similarity_df,\n",
    "        top_n=10\n",
    "    )\n",
    "\n",
    "autoencoder_recommendations = {}\n",
    "\n",
    "for user_id in eval_users:\n",
    "    autoencoder_recommendations[user_id] = autoencoder_recommend_wrapper(\n",
    "        user_id,\n",
    "        autoencoder_predicted_ratings,\n",
    "        autoencoder_matrix,\n",
    "        top_n=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e44d917-92d6-4fe8-ab7c-3b43290c34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "item_cf_metrics = evaluate_model(item_cf_recommendations, ground_truth, k)\n",
    "autoencoder_metrics = evaluate_model(autoencoder_recommendations, ground_truth, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a66192f-686f-4dfd-97eb-f5cf9a37b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "      <th>MAP@K</th>\n",
       "      <th>NDCG@K</th>\n",
       "      <th>HitRate@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item-Based CF</th>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.039572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autoencoder</th>\n",
       "      <td>0.030695</td>\n",
       "      <td>0.040101</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.032758</td>\n",
       "      <td>0.252406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision@K  Recall@K     MAP@K    NDCG@K  HitRate@K\n",
       "Item-Based CF     0.004064  0.003527  0.000680  0.003232   0.039572\n",
       "Autoencoder       0.030695  0.040101  0.010508  0.032758   0.252406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Item-Based CF\": item_cf_metrics,\n",
    "        \"Autoencoder\": autoencoder_metrics,\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recommender Env",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
