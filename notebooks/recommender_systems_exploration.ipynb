{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cbdb6a1-a1d9-4e08-aed4-5250f0dc307d",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea71cf9f-2c78-4211-bf8e-5c2078e821ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Add the root folder to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from app.etl import run_etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea8faea-4c1a-42d5-a6b8-168a575b9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to ../app/preprocessed_movielens.csv\n",
      "   user_id  movie_id  rating  timestamp                       title\n",
      "0      195       241       3  881250949                Kolya (1996)\n",
      "1      185       301       3  891717742    L.A. Confidential (1997)\n",
      "2       21       376       1  878887116         Heavyweights (1994)\n",
      "3      243        50       2  880606923  Legends of the Fall (1994)\n",
      "4      165       345       1  886397596         Jackie Brown (1997)\n"
     ]
    }
   ],
   "source": [
    "#Paths to the dataset files\n",
    "file_paths = {\n",
    "    'ratings': '../data/ml_100k/u.data',\n",
    "    'movies': '../data/ml_100k/u.item'\n",
    "}\n",
    "\n",
    "# Run the ETL pipeline\n",
    "preprocessed_data = run_etl(file_paths, save_path='../app/preprocessed_movielens.csv')\n",
    "\n",
    "# Check the resulting data\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c0587-a723-44de-9d00-75e490374853",
   "metadata": {},
   "source": [
    "# Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09517475-f39f-4efa-a1be-8717a911202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ratings dataset\n",
    "ratings = pd.read_csv('../data/ml_100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Load the movies dataset\n",
    "movies = pd.read_csv('../data/ml_100k/u.item', sep='|', encoding='latin-1', header=None,\n",
    "                     names=['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "                            'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "                            'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "                            'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea1c824-6a62-4e4c-971e-c8e611563992",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_copy = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "genres_encoded = movies[columns_to_copy].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "798f66dd-f8e0-41fd-8865-b4d739ab6e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title              Toy Story (1995)  GoldenEye (1995)  Four Rooms (1995)  \\\n",
      "title                                                                      \n",
      "Toy Story (1995)           1.000000          0.000000            0.00000   \n",
      "GoldenEye (1995)           0.000000          1.000000            0.57735   \n",
      "Four Rooms (1995)          0.000000          0.577350            1.00000   \n",
      "Get Shorty (1995)          0.333333          0.333333            0.00000   \n",
      "Copycat (1995)             0.000000          0.333333            0.57735   \n",
      "\n",
      "title              Get Shorty (1995)  Copycat (1995)  \\\n",
      "title                                                  \n",
      "Toy Story (1995)            0.333333        0.000000   \n",
      "GoldenEye (1995)            0.333333        0.333333   \n",
      "Four Rooms (1995)           0.000000        0.577350   \n",
      "Get Shorty (1995)           1.000000        0.333333   \n",
      "Copycat (1995)              0.333333        1.000000   \n",
      "\n",
      "title              Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)  \\\n",
      "title                                                                     \n",
      "Toy Story (1995)                                             0.00000      \n",
      "GoldenEye (1995)                                             0.00000      \n",
      "Four Rooms (1995)                                            0.00000      \n",
      "Get Shorty (1995)                                            0.57735      \n",
      "Copycat (1995)                                               0.57735      \n",
      "\n",
      "title              Twelve Monkeys (1995)  Babe (1995)  \\\n",
      "title                                                   \n",
      "Toy Story (1995)                0.000000     0.666667   \n",
      "GoldenEye (1995)                0.000000     0.000000   \n",
      "Four Rooms (1995)               0.000000     0.000000   \n",
      "Get Shorty (1995)               0.408248     0.666667   \n",
      "Copycat (1995)                  0.408248     0.333333   \n",
      "\n",
      "title              Dead Man Walking (1995)  Richard III (1995)  ...  \\\n",
      "title                                                           ...   \n",
      "Toy Story (1995)                   0.00000            0.000000  ...   \n",
      "GoldenEye (1995)                   0.00000            0.000000  ...   \n",
      "Four Rooms (1995)                  0.00000            0.000000  ...   \n",
      "Get Shorty (1995)                  0.57735            0.408248  ...   \n",
      "Copycat (1995)                     0.57735            0.408248  ...   \n",
      "\n",
      "title              Mirage (1995)  Mamma Roma (1962)  Sunchaser, The (1996)  \\\n",
      "title                                                                        \n",
      "Toy Story (1995)        0.000000            0.00000                0.00000   \n",
      "GoldenEye (1995)        0.816497            0.00000                0.00000   \n",
      "Four Rooms (1995)       0.707107            0.00000                0.00000   \n",
      "Get Shorty (1995)       0.408248            0.57735                0.57735   \n",
      "Copycat (1995)          0.408248            0.57735                0.57735   \n",
      "\n",
      "title              War at Home, The (1996)  Sweet Nothing (1995)  \\\n",
      "title                                                              \n",
      "Toy Story (1995)                   0.00000               0.00000   \n",
      "GoldenEye (1995)                   0.00000               0.00000   \n",
      "Four Rooms (1995)                  0.00000               0.00000   \n",
      "Get Shorty (1995)                  0.57735               0.57735   \n",
      "Copycat (1995)                     0.57735               0.57735   \n",
      "\n",
      "title              Mat' i syn (1997)  B. Monkey (1998)  Sliding Doors (1998)  \\\n",
      "title                                                                          \n",
      "Toy Story (1995)             0.00000          0.000000              0.000000   \n",
      "GoldenEye (1995)             0.00000          0.408248              0.000000   \n",
      "Four Rooms (1995)            0.00000          0.707107              0.000000   \n",
      "Get Shorty (1995)            0.57735          0.000000              0.408248   \n",
      "Copycat (1995)               0.57735          0.408248              0.408248   \n",
      "\n",
      "title              You So Crazy (1994)  \\\n",
      "title                                    \n",
      "Toy Story (1995)               0.57735   \n",
      "GoldenEye (1995)               0.00000   \n",
      "Four Rooms (1995)              0.00000   \n",
      "Get Shorty (1995)              0.57735   \n",
      "Copycat (1995)                 0.00000   \n",
      "\n",
      "title              Scream of Stone (Schrei aus Stein) (1991)  \n",
      "title                                                         \n",
      "Toy Story (1995)                                     0.00000  \n",
      "GoldenEye (1995)                                     0.00000  \n",
      "Four Rooms (1995)                                    0.00000  \n",
      "Get Shorty (1995)                                    0.57735  \n",
      "Copycat (1995)                                       0.57735  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(genres_encoded)\n",
    "\n",
    "# Wrap it in a dataFrame for easy access\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=movies['title'], columns=movies['title'])\n",
    "\n",
    "# check the similarity matrix\n",
    "print(similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376dd05b-eae1-44b8-b8fb-8ecf2d7830b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Aladdin and the King of Thieves (1996)    1.000000\n",
      "Aladdin (1992)                            0.866025\n",
      "Goofy Movie, A (1995)                     0.866025\n",
      "Jungle2Jungle (1997)                      0.816497\n",
      "Angels in the Outfield (1994)             0.816497\n",
      "Name: Toy Story (1995), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(movie_title, similarity_df, top_n=5):\n",
    "    # Get similarity scores for the given movie\n",
    "    similar_movies = similarity_df[movie_title].sort_values(ascending=False)\n",
    "\n",
    "    # Exclude the movie itself\n",
    "    similar_movies = similar_movies.drop(movie_title)\n",
    "\n",
    "    # Return the top N recommendations\n",
    "    return similar_movies.head(top_n)\n",
    "\n",
    "\n",
    "# example: Recommend similar movies to \"Toy Story (1995)\"\n",
    "recommendations = recommend_movies(\"Toy Story (1995)\", similarity_df)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0332c9-b00c-4ed2-969c-558caad5d93a",
   "metadata": {},
   "source": [
    "# 1. User-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef030225-95b5-4609-b1d8-8f7501d5b7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix:\n",
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "1          5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
      "2          4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n",
      "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "5          4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "939        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n",
      "940        0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n",
      "941        5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n",
      "942        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "943        0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n",
      "\n",
      "movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "939        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "940        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "941        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "942        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "943        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[943 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a user-item matrix\n",
    "user_item_matrix = ratings.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "\n",
    "# Fill NaN with 0 (users may not have rated all movies)\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "np.save('user_item_matrix.npy', user_item_matrix)\n",
    "\n",
    "# Check the user-item matrix\n",
    "print(\"User-Item Matrix:\")\n",
    "print(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7429b9a5-8be9-4170-a97f-38d55514dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Similarity Matrix:\n",
      "user_id       1         2         3         4         5         6         7    \\\n",
      "user_id                                                                         \n",
      "1        1.000000  0.166931  0.047460  0.064358  0.378475  0.430239  0.440367   \n",
      "2        0.166931  1.000000  0.110591  0.178121  0.072979  0.245843  0.107328   \n",
      "3        0.047460  0.110591  1.000000  0.344151  0.021245  0.072415  0.066137   \n",
      "4        0.064358  0.178121  0.344151  1.000000  0.031804  0.068044  0.091230   \n",
      "5        0.378475  0.072979  0.021245  0.031804  1.000000  0.237286  0.373600   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "939      0.118095  0.228583  0.026271  0.030138  0.071459  0.111852  0.107027   \n",
      "940      0.314072  0.226790  0.161890  0.196858  0.239955  0.352449  0.329925   \n",
      "941      0.148617  0.161485  0.101243  0.152041  0.139595  0.144446  0.059993   \n",
      "942      0.179508  0.172268  0.133416  0.170086  0.152497  0.317328  0.282003   \n",
      "943      0.398175  0.105798  0.026556  0.058752  0.313941  0.276042  0.394364   \n",
      "\n",
      "user_id       8         9         10   ...       934       935       936  \\\n",
      "user_id                                ...                                 \n",
      "1        0.319072  0.078138  0.376544  ...  0.369527  0.119482  0.274876   \n",
      "2        0.103344  0.161048  0.159862  ...  0.156986  0.307942  0.358789   \n",
      "3        0.083060  0.061040  0.065151  ...  0.031875  0.042753  0.163829   \n",
      "4        0.188060  0.101284  0.060859  ...  0.052107  0.036784  0.133115   \n",
      "5        0.248930  0.056847  0.201427  ...  0.338794  0.080580  0.094924   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "939      0.095898  0.039852  0.071460  ...  0.066039  0.431154  0.258021   \n",
      "940      0.246883  0.120495  0.342961  ...  0.327153  0.107024  0.187536   \n",
      "941      0.146145  0.143245  0.090305  ...  0.046952  0.203301  0.288318   \n",
      "942      0.175322  0.092497  0.212330  ...  0.226440  0.073513  0.089588   \n",
      "943      0.299809  0.075617  0.221860  ...  0.263791  0.210763  0.143253   \n",
      "\n",
      "user_id       937       938       939       940       941       942       943  \n",
      "user_id                                                                        \n",
      "1        0.189705  0.197326  0.118095  0.314072  0.148617  0.179508  0.398175  \n",
      "2        0.424046  0.319889  0.228583  0.226790  0.161485  0.172268  0.105798  \n",
      "3        0.069038  0.124245  0.026271  0.161890  0.101243  0.133416  0.026556  \n",
      "4        0.193471  0.146058  0.030138  0.196858  0.152041  0.170086  0.058752  \n",
      "5        0.079779  0.148607  0.071459  0.239955  0.139595  0.152497  0.313941  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "939      0.226449  0.432666  1.000000  0.087687  0.180029  0.043264  0.144250  \n",
      "940      0.181317  0.175158  0.087687  1.000000  0.145152  0.261376  0.241028  \n",
      "941      0.234211  0.313400  0.180029  0.145152  1.000000  0.101642  0.095120  \n",
      "942      0.129554  0.099385  0.043264  0.261376  0.101642  1.000000  0.182465  \n",
      "943      0.077793  0.202244  0.144250  0.241028  0.095120  0.182465  1.000000  \n",
      "\n",
      "[943 rows x 943 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cosine similarity between users\n",
    "user_similarity = cosine_similarity(user_item_matrix)\n",
    "\n",
    "# Wrap it in a dataFrame for easy access\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "# Check the user similarity matrix\n",
    "print(\"User Similarity Matrix:\")\n",
    "print(user_similarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00327f56-925c-44fb-b001-955e62d30a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Based Recommendations:\n",
      "                                    title  weighted_rating\n",
      "0                 Schindler's List (1993)         2.035432\n",
      "1       E.T. the Extra-Terrestrial (1982)         1.871222\n",
      "2  One Flew Over the Cuckoo's Nest (1975)         1.792122\n",
      "3             English Patient, The (1996)         1.742431\n",
      "4                           Scream (1996)         1.696068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_user_based(user_id, user_item_matrix, user_similarity_df, top_n=5):\n",
    "    # Get the similarity scores for the target user\n",
    "    similar_users = user_similarity_df[user_id]\n",
    "\n",
    "    # Calculate weighted ratings\n",
    "    weighted_ratings = np.dot(similar_users, user_item_matrix) / similar_users.sum()\n",
    "\n",
    "    # Create a dataFrame with weighted ratings\n",
    "    recommendations = pd.DataFrame({\n",
    "        'movie_id': user_item_matrix.columns,\n",
    "        'weighted_rating': weighted_ratings\n",
    "    }).sort_values(by='weighted_rating', ascending=False)\n",
    "\n",
    "    # Exclude movies the user has already rated\n",
    "    user_rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "    recommendations = recommendations[~recommendations['movie_id'].isin(user_rated_movies)]\n",
    "\n",
    "    # Merge with movie titles for readability\n",
    "    recommendations = recommendations.merge(movies, on='movie_id')\n",
    "\n",
    "    return recommendations[['title', 'weighted_rating']].head(top_n)\n",
    "\n",
    "# example: Recommend movies for userId = 1\n",
    "user_recommendations = recommend_user_based(1, user_item_matrix, user_similarity_df)\n",
    "print(\"User-Based Recommendations:\")\n",
    "print(user_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4b99f-e8e3-42ba-993a-a73947208eeb",
   "metadata": {},
   "source": [
    "#  Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a33950-251b-4063-8625-bc508bcde26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Similarity Matrix:\n",
      "movie_id      1         2         3         4         5         6     \\\n",
      "movie_id                                                               \n",
      "1         1.000000  0.402382  0.330245  0.454938  0.286714  0.116344   \n",
      "2         0.402382  1.000000  0.273069  0.502571  0.318836  0.083563   \n",
      "3         0.330245  0.273069  1.000000  0.324866  0.212957  0.106722   \n",
      "4         0.454938  0.502571  0.324866  1.000000  0.334239  0.090308   \n",
      "5         0.286714  0.318836  0.212957  0.334239  1.000000  0.037299   \n",
      "\n",
      "movie_id      7         8         9         10    ...      1673  1674  \\\n",
      "movie_id                                          ...                   \n",
      "1         0.620979  0.481114  0.496288  0.273935  ...  0.035387   0.0   \n",
      "2         0.383403  0.337002  0.255252  0.171082  ...  0.000000   0.0   \n",
      "3         0.372921  0.200794  0.273669  0.158104  ...  0.000000   0.0   \n",
      "4         0.489283  0.490236  0.419044  0.252561  ...  0.000000   0.0   \n",
      "5         0.334769  0.259161  0.272448  0.055453  ...  0.000000   0.0   \n",
      "\n",
      "movie_id      1675      1676      1677  1678  1679  1680      1681      1682  \n",
      "movie_id                                                                      \n",
      "1         0.000000  0.000000  0.035387   0.0   0.0   0.0  0.047183  0.047183  \n",
      "2         0.000000  0.000000  0.000000   0.0   0.0   0.0  0.078299  0.078299  \n",
      "3         0.000000  0.000000  0.032292   0.0   0.0   0.0  0.000000  0.096875  \n",
      "4         0.094022  0.094022  0.037609   0.0   0.0   0.0  0.056413  0.075218  \n",
      "5         0.000000  0.000000  0.000000   0.0   0.0   0.0  0.000000  0.094211  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transpose user-item matrix\n",
    "item_user_matrix = user_item_matrix.T\n",
    "\n",
    "# Calculate cosine similarity between movies\n",
    "item_similarity = cosine_similarity(item_user_matrix)\n",
    "\n",
    "# Wrap it in a dataFrame for easy access\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=item_user_matrix.index, columns=item_user_matrix.index)\n",
    "\n",
    "# Check the item similarity matrix\n",
    "print(\"Item Similarity Matrix:\")\n",
    "print(item_similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc5ac30-8a58-4834-baba-b924b4dacd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-Based Recommendations:\n",
      "                                       title     score\n",
      "0                    King of New York (1990)  1.528732\n",
      "1  Scream of Stone (Schrei aus Stein) (1991)  1.503711\n",
      "2                      Jupiter's Wife (1994)  1.488788\n",
      "3                             Witness (1985)  1.462689\n",
      "4                     All Things Fair (1996)  1.414305\n"
     ]
    }
   ],
   "source": [
    "def recommend_item_based(user_id, user_item_matrix, item_similarity_df, top_n=5):\n",
    "    # Get the user's ratings\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "\n",
    "    # Calculate scores by multiplying user's ratings with item similarity\n",
    "    scores = np.dot(user_ratings, item_similarity_df) / np.array([np.abs(item_similarity_df).sum(axis=1)])\n",
    "    scores = scores.flatten()\n",
    "\n",
    "    # Create a dataFrame with scores\n",
    "    recommendations = pd.DataFrame({\n",
    "        'movie_id': user_item_matrix.columns,\n",
    "        'score': scores\n",
    "    }).sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Exclude movies the user has already rated\n",
    "    user_rated_movies = user_ratings[user_ratings > 0].index\n",
    "    recommendations = recommendations[~recommendations['movie_id'].isin(user_rated_movies)]\n",
    "\n",
    "    # Merge with movie titles\n",
    "    recommendations = recommendations.merge(movies, on='movie_id')\n",
    "\n",
    "    return recommendations[['title', 'score']].head(top_n)\n",
    "\n",
    "# example: Recommend movies for userId = 1\n",
    "item_recommendations = recommend_item_based(1, user_item_matrix, item_similarity_df)\n",
    "print(\"Item-Based Recommendations:\")\n",
    "print(item_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990d119-cc2b-4130-a7ea-ad93d97ac50e",
   "metadata": {},
   "source": [
    "# Matrix Factorization (e.g., SVD) Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8da97e6-9769-46ee-941a-1998fad9ed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix:\n",
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "1          5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
      "2          4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n",
      "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "5          4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with 0\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "print(\"User-Item Matrix:\")\n",
    "print(user_item_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ecb59f-b93c-4f74-a8bc-d816fb5f58d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_features: (943, 20)\n",
      "Shape of item_features: (20, 1682)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply Truncated SVD\n",
    "n_components = 20  # Number of latent features\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "user_features = svd.fit_transform(user_item_matrix)\n",
    "item_features = svd.components_\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of user_features:\", user_features.shape)  # (n_users, n_components)\n",
    "print(\"Shape of item_features:\", item_features.shape)  # (n_components, n_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d2fcd86-98dd-48b2-b11d-0676580f6ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ratings Matrix:\n",
      "movie_id      1         2         3         4         5         6     \\\n",
      "user_id                                                                \n",
      "1         4.168742  2.257471  1.597417  3.101478  0.865192  0.679666   \n",
      "2         1.988409 -0.075958 -0.003907  0.487492 -0.044064  0.298416   \n",
      "3        -0.152413 -0.024778  0.169515 -0.180050 -0.123459  0.055948   \n",
      "4         0.541978 -0.162967  0.056590 -0.155267  0.078064  0.007859   \n",
      "5         3.499255  1.191323  0.285047  1.923982  0.391172 -0.207930   \n",
      "\n",
      "movie_id      7         8         9         10    ...      1673      1674  \\\n",
      "user_id                                           ...                       \n",
      "1         4.833356  2.447116  3.640474  1.864810  ... -0.017046  0.015924   \n",
      "2         1.624070  0.413328  2.497702  0.598847  ... -0.000148 -0.015717   \n",
      "3        -0.151615  0.124535 -0.332404  0.020384  ...  0.004127 -0.014259   \n",
      "4         0.349775 -0.086234 -0.133027 -0.196605  ...  0.002065 -0.009193   \n",
      "5         2.805973  1.334445 -0.454142  0.385770  ... -0.015146  0.012047   \n",
      "\n",
      "movie_id      1675      1676      1677      1678      1679      1680  \\\n",
      "user_id                                                                \n",
      "1        -0.016208 -0.010806  0.031945 -0.002290 -0.006870 -0.004580   \n",
      "2        -0.006744 -0.004496 -0.002684  0.004730  0.014190  0.009460   \n",
      "3         0.020526  0.013684 -0.002147  0.010471  0.031412  0.020941   \n",
      "4        -0.008590 -0.005726 -0.004508  0.004895  0.014684  0.009790   \n",
      "5        -0.027946 -0.018631 -0.017266 -0.002090 -0.006269 -0.004179   \n",
      "\n",
      "movie_id      1681      1682  \n",
      "user_id                       \n",
      "1         0.019238  0.083012  \n",
      "2        -0.006708 -0.032415  \n",
      "3         0.003313 -0.001033  \n",
      "4        -0.001190 -0.000293  \n",
      "5        -0.006016 -0.023363  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reconstruct the approximate user-item matrix\n",
    "reconstructed_matrix = np.dot(user_features, item_features)\n",
    "\n",
    "# Wrap it in a dataFrame for easy access\n",
    "predicted_ratings = pd.DataFrame(reconstructed_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "print(\"Predicted Ratings Matrix:\")\n",
    "print(predicted_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "452df7a6-408d-4700-a816-57269e9dce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Recommendations:\n",
      "                               title  predicted_rating\n",
      "0               Trainspotting (1996)          4.543125\n",
      "1           Leaving Las Vegas (1995)          3.688342\n",
      "2        English Patient, The (1996)          3.420426\n",
      "3  E.T. the Extra-Terrestrial (1982)          3.213485\n",
      "4                  Casablanca (1942)          3.179610\n"
     ]
    }
   ],
   "source": [
    "def recommend_svd(user_id, predicted_ratings, movies, top_n=5):\n",
    "    # Get the user's predicted ratings\n",
    "    user_predicted_ratings = predicted_ratings.loc[user_id]\n",
    "\n",
    "    # Sort by predicted rating in descending order\n",
    "    recommendations = user_predicted_ratings.sort_values(ascending=False)\n",
    "\n",
    "    # Exclude movies the user has already rated\n",
    "    user_rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "    recommendations = recommendations[~recommendations.index.isin(user_rated_movies)]\n",
    "\n",
    "    # Reset index and rename predicted ratings\n",
    "    recommendations = recommendations.reset_index()\n",
    "    recommendations.columns = ['movie_id', 'predicted_rating']  # Rename columns for clarity\n",
    "\n",
    "    # Merge with movie titles\n",
    "    recommendations = recommendations.merge(movies, on='movie_id')\n",
    "\n",
    "    return recommendations[['title', 'predicted_rating']].head(top_n)\n",
    "\n",
    "\n",
    "svd_recommendations = recommend_svd(1, predicted_ratings, movies)\n",
    "print(\"SVD Recommendations:\")\n",
    "print(svd_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f59c28-66b0-4988-8dd7-af95ab3352d0",
   "metadata": {},
   "source": [
    "# Deep Learning-Based Recommendation Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da9414-d85a-45cf-a513-bb04b48563ed",
   "metadata": {},
   "source": [
    "## Autoencoders for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "438257a1-396d-41f8-93a7-f6bbd131b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (754, 1682)\n",
      "Testing Shape: (189, 1682)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the user-item matrix (row-wise normalization)\n",
    "normalized_matrix = scaler.fit_transform(user_item_matrix)\n",
    "\n",
    "# Convert back to a dataFrame\n",
    "normalized_matrix = pd.DataFrame(normalized_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Split into training and test sets\n",
    "train, test = train_test_split(normalized_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "train = train.values\n",
    "test = test.values\n",
    "\n",
    "print(\"Training Shape:\", train.shape)\n",
    "print(\"Testing Shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbabb79-892b-40a3-a6f3-32301daf7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "n_movies = user_item_matrix.shape[1]  # Number of movies (columns)\n",
    "\n",
    "autoencoder = models.Sequential([\n",
    "    layers.Input(shape=(n_movies,)),  # Input layer\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer (encoding)\n",
    "    layers.Dense(64, activation='relu'),   # Bottleneck (latent features)\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer (decoding)\n",
    "    layers.Dense(n_movies, activation='sigmoid')  # Output layer (reconstructed ratings)\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')  # Mean Squared Error for reconstruction loss\n",
    "\n",
    "# Summary\n",
    "autoencoder.summary()\n",
    "\n",
    "plot_model(autoencoder, to_file=\"autoencoder_architecture.png\", show_shapes=True, show_layer_names=True)\n",
    "print(\"Autoencoder architecture saved as 'autoencoder_architecture.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb021b8-40bf-4d8c-83de-cc835096818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    train, train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(test, test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e566b2-d1f7-4007-b97c-da852111fb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Predicted Ratings (Autoencoder):\n",
      "movie_id      1             2             3         4         5     \\\n",
      "user_id                                                              \n",
      "1         0.999964  9.999831e-01  9.971140e-01  1.000000  0.835094   \n",
      "2         0.007410  1.314198e-09  2.309043e-05  0.000018  0.001771   \n",
      "3         0.000002  2.123803e-07  4.557213e-06  0.007998  0.001848   \n",
      "4         0.000088  7.756667e-09  7.194463e-06  0.000071  0.004572   \n",
      "5         0.790437  8.885342e-01  5.293274e-07  0.008950  0.002607   \n",
      "\n",
      "movie_id          6         7             8             9         10    ...  \\\n",
      "user_id                                                                 ...   \n",
      "1         9.812189e-01  1.000000  9.700170e-01  9.556419e-01  0.907717  ...   \n",
      "2         8.616745e-05  0.000644  1.161575e-03  2.806466e-01  0.007110  ...   \n",
      "3         3.000294e-04  0.000844  5.888203e-07  9.520559e-07  0.000004  ...   \n",
      "4         1.545838e-03  0.008472  1.700872e-05  6.170564e-06  0.000028  ...   \n",
      "5         2.517968e-07  0.054627  2.186014e-01  5.729321e-13  0.000006  ...   \n",
      "\n",
      "movie_id          1673          1674          1675          1676  \\\n",
      "user_id                                                            \n",
      "1         3.110520e-12  5.232156e-11  7.276716e-16  1.670279e-12   \n",
      "2         1.455473e-13  1.822799e-10  3.651897e-14  4.647655e-13   \n",
      "3         1.416947e-12  3.048430e-10  1.975996e-11  6.048148e-10   \n",
      "4         2.846426e-12  8.441422e-10  1.538555e-11  4.692958e-10   \n",
      "5         7.940810e-12  4.682889e-14  1.454893e-13  1.751263e-11   \n",
      "\n",
      "movie_id          1677          1678          1679          1680  \\\n",
      "user_id                                                            \n",
      "1         6.173595e-13  8.739288e-13  2.095549e-13  1.637370e-12   \n",
      "2         2.020691e-12  4.059353e-12  5.137162e-16  4.311164e-12   \n",
      "3         1.079557e-09  2.608576e-09  2.058501e-13  1.316581e-10   \n",
      "4         5.242607e-10  8.504141e-10  1.709337e-12  2.965451e-10   \n",
      "5         2.533032e-14  2.760973e-15  4.894518e-15  7.725784e-15   \n",
      "\n",
      "movie_id          1681          1682  \n",
      "user_id                               \n",
      "1         1.580822e-06  1.887227e-08  \n",
      "2         2.302684e-16  1.146406e-10  \n",
      "3         6.080079e-11  8.129114e-10  \n",
      "4         5.460675e-12  4.163944e-10  \n",
      "5         1.627382e-08  8.905062e-13  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict the reconstructed user-item matrix\n",
    "reconstructed_matrix = autoencoder.predict(normalized_matrix)\n",
    "\n",
    "# Ensure the reconstructed matrix matches the original dataFrame's shape\n",
    "predicted_ratings = pd.DataFrame(reconstructed_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "print(\"Predicted Ratings (Autoencoder):\")\n",
    "print(predicted_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51da7276-d8e9-464b-a56a-08044d066574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Recommendations:\n",
      "                                               title  predicted_rating\n",
      "0  Dr. Strangelove or: How I Learned to Stop Worr...          1.000000\n",
      "1                                 Stand by Me (1986)          1.000000\n",
      "2                                      Batman (1989)          1.000000\n",
      "3                  Jackie Chan's First Strike (1996)          1.000000\n",
      "4      William Shakespeare's Romeo and Juliet (1996)          0.999999\n"
     ]
    }
   ],
   "source": [
    "def recommend_deep_learning(user_id, predicted_ratings, movies, top_n=5):\n",
    "    # Get the user's predicted ratings\n",
    "    user_predicted_ratings = predicted_ratings.loc[user_id].sort_values(ascending=False)\n",
    "\n",
    "    # Exclude movies the user has already rated\n",
    "    user_rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "    recommendations = user_predicted_ratings[~user_predicted_ratings.index.isin(user_rated_movies)]\n",
    "\n",
    "    # Convert recommendations to dataFrame\n",
    "    recommendations = recommendations.reset_index()\n",
    "    recommendations.columns = ['movie_id', 'predicted_rating']  # Rename columns for clarity\n",
    "\n",
    "    # Merge with movie titles\n",
    "    recommendations = recommendations.merge(movies, on='movie_id')\n",
    "\n",
    "    return recommendations[['title', 'predicted_rating']].head(top_n)\n",
    "\n",
    "# example: Recommend movies for userId = 1\n",
    "deep_learning_recommendations = recommend_deep_learning(1, predicted_ratings, movies)\n",
    "print(\"Deep Learning Recommendations:\")\n",
    "print(deep_learning_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2714690-942e-4104-b6bc-96c15248f686",
   "metadata": {},
   "source": [
    "## RNNs for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8f558ac-4a83-47d8-9ec5-17892dc5d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MovieLens dataset\n",
    "df = ratings.copy()  \n",
    "movies = movies.copy()  # Movie metadata\n",
    "\n",
    "# Sort by timestamp to create sequences\n",
    "df = df.sort_values(by=['user_id', 'timestamp'])\n",
    "\n",
    "# Map users and movies to unique IDs\n",
    "user_ids = df['user_id'].unique()\n",
    "movie_ids = df['movie_id'].unique()\n",
    "\n",
    "user_id_map = {user: idx for idx, user in enumerate(user_ids)}\n",
    "movie_id_map = {movie: idx for idx, movie in enumerate(movie_ids)}\n",
    "\n",
    "np.save('movie_id_map.npy', movie_id_map)\n",
    "\n",
    "ratings['user_id'] = ratings['user_id'].map(user_id_map)\n",
    "ratings['movie_id'] = ratings['movie_id'].map(movie_id_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5be4827e-8151-4fc6-80ac-f37929918411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 1682, Max movieId in X: 1681\n",
      "X_train shape: (76228, 5), y_train shape: (76228,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: 6.9022 - val_accuracy: 0.0060 - val_loss: 6.7625\n",
      "Epoch 2/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.0045 - loss: 6.7320 - val_accuracy: 0.0054 - val_loss: 6.6801\n",
      "Epoch 3/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.0050 - loss: 6.6038 - val_accuracy: 0.0068 - val_loss: 6.6070\n",
      "Epoch 4/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.0066 - loss: 6.5250 - val_accuracy: 0.0055 - val_loss: 6.5892\n",
      "Epoch 5/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.0066 - loss: 6.4703 - val_accuracy: 0.0062 - val_loss: 6.5727\n",
      "Epoch 6/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.0081 - loss: 6.4041 - val_accuracy: 0.0057 - val_loss: 6.5824\n",
      "Epoch 7/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.0085 - loss: 6.3564 - val_accuracy: 0.0056 - val_loss: 6.6009\n",
      "Epoch 8/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.0098 - loss: 6.2972 - val_accuracy: 0.0055 - val_loss: 6.6421\n",
      "Epoch 9/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.0124 - loss: 6.2194 - val_accuracy: 0.0050 - val_loss: 6.6838\n",
      "Epoch 10/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.0159 - loss: 6.1400 - val_accuracy: 0.0049 - val_loss: 6.7301\n"
     ]
    }
   ],
   "source": [
    "# Group ratings by user and create sequences of movie IDs\n",
    "user_sequences = ratings.groupby('user_id')['movie_id'].apply(list)\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 5\n",
    "\n",
    "# Create input (X) and output (y) sequences\n",
    "X, y = [], []\n",
    "for seq in user_sequences:\n",
    "    for i in range(len(seq) - sequence_length):\n",
    "        X.append(seq[i:i + sequence_length])  # Last `sequence_length` movies\n",
    "        y.append(seq[i + sequence_length])   # Next movie\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Verify the maximum movie ID (should match input_dim for the embedding layer)\n",
    "num_movies = len(movie_id_map)\n",
    "print(f\"Number of movies: {num_movies}, Max movie_id in X: {X.max()}\")\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pad sequences to ensure consistent input length\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, padding='pre')\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, padding='pre')\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "embedding_size = 50\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_movies, output_dim=embedding_size, input_length=sequence_length),\n",
    "    LSTM(128, return_sequences=False),  # Use LSTM to process sequences\n",
    "    Dense(num_movies, activation='softmax')  # Output layer for movie prediction\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,  # Adjust epochs as needed\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe2764de-bc9f-4a6b-8607-eea8282840ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Movies: [np.int64(173), np.int64(210), np.int64(679), np.int64(68), np.int64(385)]\n",
      "Recommended Movie Titles: ['Crow, The (1994)', 'Princess Bride, The (1987)', 'Indiana Jones and the Last Crusade (1989)', 'True Lies (1994)', 'Conan the Barbarian (1981)']\n"
     ]
    }
   ],
   "source": [
    "def recommend_next_movies(user_sequence, model, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend the next movies for a given sequence.\n",
    "    \n",
    "    Args:\n",
    "    - user_sequence: List of movie IDs (most recent interactions).\n",
    "    - model: Trained RNN model.\n",
    "    - top_n: Number of recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of recommended movie IDs.\n",
    "    \"\"\"\n",
    "    # Pad the sequence to match the model's input length\n",
    "    padded_sequence = pad_sequences([user_sequence], maxlen=sequence_length, padding='pre')\n",
    "\n",
    "    # Predict the probabilities for the next movie\n",
    "    predictions = model.predict(padded_sequence, verbose=0)\n",
    "    top_movie_ids = np.argsort(predictions[0])[-top_n:][::-1]  # Top-N movie indices\n",
    "\n",
    "    # Map back to original movie IDs\n",
    "    return [list(movie_id_map.keys())[idx] for idx in top_movie_ids]\n",
    "\n",
    "# example: Recommend the next movies for a user\n",
    "sample_user_sequence = X_test[0]  # Use a sequence from the test set\n",
    "recommended_movies = recommend_next_movies(sample_user_sequence, model)\n",
    "print(\"Recommended Movies:\", recommended_movies)\n",
    "\n",
    "# Map movie IDs back to titles\n",
    "recommended_titles = movies[movies['movie_id'].isin(recommended_movies)]['title']\n",
    "print(\"Recommended Movie Titles:\", recommended_titles.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f951bcaa-721d-4938-9e4b-1f509bb9b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('autoencoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d278cda-2c86-4898-9ecb-88f785eaa959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; \n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras; \n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d766c-5d5c-4b74-bc89-15424b7ef62c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test_recommender)",
   "language": "python",
   "name": "test_recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
